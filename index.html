<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Pranit Chawla - Applied Scientist II">
    <title>Pranit Chawla</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="site-header">
        <div class="container header-content">
            <div class="site-brand">Pranit Chawla</div>
        </div>
    </header>

    <main class="container">
        <section id="home" class="hero">
            <div class="hero-grid">
                <div class="hero-text">
                    <p class="hero-summary">
                        I am currently building the next generation of computer-using agents for M365 and windows. We are using end to end online reinforcement learning to improve agents to use GUI based applications and operating systems, allowing users to complete tasks on their OS through copilot. I also collaborate closely with OpenAI on improving the general manipulation and grounding capabilities of CUAs. I am also working on improving reasoning for multi-modal LLMs, improving agentic reasoning and memory, and knowledge distillation from strong agentic teacher models to smaller models (~7B-14B).
                    </p>
                    <p class="hero-summary">
                        I previously graduated from Carnegie Mellon University with a masters degree in machine learning, where I worked with Prof. Zico Kolter on exploring efficient ways to mine negatives for training CLIP style multi-modal models.
                    </p>
                    <div class="hero-links">
                    </div>
                </div>
                <div class="hero-media">
                    <img class="hero-image" src="assets/profile.png" alt="Pranit Chawla profile photo">
                    <div class="hero-links">
                        <a href="https://scholar.google.com/citations?user=v8hTveEAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a>
                        <span>/</span>
                        <a href="https://linkedin.com/in/pranitchawla" target="_blank" rel="noopener noreferrer">LinkedIn</a>
                    </div>
                </div>
            </div>
        </section>

        <section id="publications" class="section">
            <heading>Publications &amp; Patents</heading>
            <div class="pub-grid">
                <article class="pub-item">
                    <img class="pub-image" src="assets/publications/figures/step-level-filtering.png" alt="Overview figure from Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering">
                    <div class="pub-details">
                        <p class="pub-title">
                            <a href="https://arxiv.org/abs/2512.10962" target="_blank" rel="noopener noreferrer">Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering</a>
                        </p>
                        <p class="pub-meta">Preprint 2025, under review.</p>
                    </div>
                </article>
                <article class="pub-item">
                    <img class="pub-image" src="assets/publications/figures/diffusion-tta.png" alt="Method diagram from Leveraging Diffusion Models for Test-time Adaptation via Pseudo-label Ensembling">
                    <div class="pub-details">
                        <p class="pub-title">
                            <a href="https://arxiv.org/abs/2311.18071" target="_blank" rel="noopener noreferrer">Leveraging Diffusion Models for Test-time Adaptation via Pseudo-label Ensembling</a>
                        </p>
                        <p class="pub-meta">NeurIPS 2023 Workshop on Distribution Shifts.</p>
                    </div>
                </article>
                <article class="pub-item">
                    <img class="pub-image" src="assets/publications/figures/hateproof.png" alt="Experiment schematic from HateProof: Are Hateful Meme Detection Systems really Robust?">
                    <div class="pub-details">
                        <p class="pub-title">
                            <a href="https://arxiv.org/abs/2302.05703" target="_blank" rel="noopener noreferrer">HateProof: Are Hateful Meme Detection Systems really Robust?</a>
                        </p>
                        <p class="pub-meta">TheWebConf 2023.</p>
                    </div>
                </article>
                <article class="pub-item">
                    <img class="pub-image" src="assets/publications/figures/style-content-retrieval.png" alt="Overview figure from Leveraging Style and Content Features for Text Conditioned Image Retrieval">
                    <div class="pub-details">
                        <p class="pub-title">
                            <a href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Chawla_Leveraging_Style_and_Content_Features_for_Text_Conditioned_Image_Retrieval_CVPRW_2021_paper.html" target="_blank" rel="noopener noreferrer">Leveraging Style and Content Features for Text Conditioned Image Retrieval</a>
                            <a href="https://www.youtube.com/watch?v=uptVpdtW6Ek" target="_blank" rel="noopener noreferrer">[Video]</a>
                        </p>
                        <p class="pub-meta">CVPR Workshops 2021. Patent filed at US-PTO.</p>
                    </div>
                </article>
                <article class="pub-item">
                    <img class="pub-image" src="assets/publications/figures/sac-retrieval.png" alt="Intro figure from SAC: Semantic Attention Composition for Text-Conditioned Image Retrieval">
                    <div class="pub-details">
                        <p class="pub-title">
                            <a href="https://arxiv.org/abs/2009.01485" target="_blank" rel="noopener noreferrer">SAC: Semantic Attention Composition for Text-Conditioned Image Retrieval</a>
                        </p>
                        <p class="pub-meta">WACV 2022. Patent filed at US-PTO.</p>
                    </div>
                </article>
            </div>
        </section>

        <section id="skills" class="section">
            <heading>Technical Skills</heading>
            <div class="tags">
                <span>PyTorch</span>
                <span>Huggingface</span>
                <span>DeepSpeed</span>
                <span>LLamaFactory</span>
                <span>vLLM</span>
                <span>Python</span>
                <span>Git</span>
                <span>Linux</span>
                <span>Flask</span>
            </div>
        </section>

        <section id="contact" class="section contact">
            <heading>Contact</heading>
            <p>
                If you'd like to collaborate or discuss research, feel free to reach out.
            </p>
        </section>
    </main>

    <footer class="footer">
        <div class="container footer-content">
            <p>&copy; <span id="current-year"></span> Pranit Chawla</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
